
```
LINUX
What is an inode?
What is process id 1, and why is it needed
What are the information contained in an inode
Difference between hard link and soft link
What happens when you type curl google.com
how would you ssh to a machine 
Talk about virtual memory for 10 minutes
What is the load average?
What command would I use to see the process using the most memory?
Where can I find information about processes in the file system?
Difference between containers and VM




```

- Minimum of 4 years working experience as a DevOps Engineer
    
- Work experience with AWS services (EC2, ELB, EBS, VPC, S3, SES, RDS, Route53) and other cloud-based computing administration like Linode, Digital Ocean, Azure etc.
    
- Hands-on experience with Infrastructure as Code, preferably Terraform.
    
- Experience with containerization technologies like Docker.
    
- Proficiency in orchestrate technology such as Kubernetes.
    
- Experience with CI and deployment tools such as GitHub Actions, Travis CI, etc.
    
- Able to configure and maintain DB servers (MySQL, Postgresql, SQL server etc.)
    
- Hands-on experience with application and web servers like Apache and Ngnix etc.
    
- Solid hands-on expertise with Linux, including system installation/configuration, file system concepts, resource monitoring, user administration, package management, and process control/management (Preferred platforms Ubuntu, Centos and Amazon AMI)
    
- Knowledge of scripting/programming in any of the administrative languages (Bash, Python, Go etc.), and working knowledge of full-stack programming is a plus.
    
- Knowledge and concept of web-based security and testing tools and methodology (mod_security, pen-testing, OS hardening, web and app server hardening)
    
- Working knowledge of networking principles and applications/technologies and routing (e.g., TCP / UDP protocols, DNS, DHCP services)
    
- Experience with GIT, or other version control source code repositories
    
- Experience with logging tools (Preferably Syslog, Rsyslog, Syslog-ng)
    
- Hands-on experience with Zabbix, Nagios, MRTG, New Relic, Data Dog or other systems monitoring software
    
- Strong interpersonal and communication skills, able to train users on topics, provide presentations to an internal audience, write documentation, and interact positively with and receive direction from upper management
    
- Mentor and share knowledge within the team and help in the continuous growth of junior team members.
    
- Highly motivated and self-driven, capable of working with little instruction to resolve demanding tasks, as well as working with internal teams

**What You’ll Need**

-   Demonstratable knowledge of management and administration of RedHat/CentOS Linux systems- things like System Installation, Package Management, OS tuning and Security Hardening.
-   Experience working in a production environment (change control, rollback plans, etc).
-   Ability to code/script– e.g. Bash, Python, Golang, etc.
-   Experience with monitoring tools like Graylog, DataDog, Dynatrace, Nagios.
-   Excellent verbal and written communication skills.
-   Bachelors degree or equivalent experience.
-   5+ years working in a technical position.
-   Ability and desire to learn quickly.

**Extra Pluses**

-   Experience with Kubernetes cluster provisioning, management and operation.
-   Experience with orchestration/config management tools like Ansible and GitHub Actions.
-   Experience with enterprise RDBMS such as MySQL.
-   Experience with Secret Management tools such as Hashicorp Vault.

**You'll Get To**

-   Build tools and frameworks to monitor systems and ensure highest level of uptime on production environments.
-   Participate and improve our 24/7 on call and incident management process. Build and maintain Run-bsooks. Contribute to the design and documentation of the cloud services and SOPs.
-   Work closely with Architects, DBAs, Developers, DevOps, Data engineers from design to production while building reliable, scalable and cost optimized services.
-   Collaborate with Service Owners to define the SLOs and build SLIs to ensure systems are meeting the SLAs.
-   Participate in blameless post-mortems. Assist in publishing RCA documents for internal and external consumption.
-   Reduce Operational Toil and maintain high degree of automation by adapting IaC first and Gitops principals.
-   Acquire and maintain significant understanding of Lytx production services to ensure timely resolution of production incidents.

**You'll Need**

-   5+ years of experience as a SRE in an AWS environment at medium to large scale organization.
-   5+ years of hands-on experience implementing and managing Observability tools (Prometheus, New Relic, Grafana, etc.)
-   High level of programing proficiency, preferably using Python, groovy and bash.
-   Good understanding of database technologies (SQL and NoSQL)
-   3+ years of experience building Infrastructure deployment pipelines leveraging git, Terraform, Helm, Jenkins/JenkinX/ArgoCD etc.
-   Proven experience in designing production environments in AWS cloud using various AWS services (VPCs, EKS, IAM, AMI, EC2, CloudWatch, CloudTrail’s, Control Tower, Guard duty, MSK, S3, Glacier, Gateways, Direct Connects, Route53, RDS, ALBs, Autoscaling etc)
-   Hands-on experience with Linux systems and various protocols and technologies (HTTP, REST, TCP/IP, SSL, DNS, SMTP, SSH, NTP, Load Balancing, SQL/NoSQL, Message Brokers, Nginx, Vault etc)
-   Hands-on experience with Kubernetes and various container and cloud native technologies.
-   Significant experience in participating, implementing, and managing 24-7 on call rotation for SRE team, creating run bsooks, building support procedures and proactively monitor systems across geographical locations
-   Ability to work well under pressure within a technically challenging environment.

**Preferred Experience**

-   Hands-on experience managing complex networks in AWS cloud (Direct Connects, Transit gateways, VPNs, BGP, Firewalls, CDNs)
-   Hands-on experience with cloud databases (Mongo, RDS, Snowflake)
-   Certifications: AWS, Kubernetes, Linux, Programming, CI/CD.

**Required Skills**

-   Demonstrated experience following software engineering best-practices
-   In-depth understanding of Unix/Linux systems internals and networking
-   Solid grounding in information security principles
-   Experience with automation and configuration management tools
-   Experience in public cloud services and deployment (AWS experience preferred)
-   Strong software development experience in one of these languages: Go, Python or Java (Python and Go preferred)
-   Knowledge of the software development lifecycle with experience integrating Open-Source tools
-   Experienced user of one or more source code management tools (Git preferred)
-   Experience with Continuous Integration and Continuous Delivery/Deployment tools like Jenkins, Bamboo, or similar
-   Experience in developing tools for system configuration, deployment, and monitoring
-   Experience deploying and maintaining services in AWS (CloudFormation, Route53, EC2, EKS)
-   Demonstrated experience writing automation for IaC (Infrastructure as Code)
-   In-depth knowledge with observability tools such as Datadog, Grafana, LightStep, Loki, and Splunk.
-   Strong belief in driving operational excellence with owning efficiency and automation at the core of operations

**Preferred Skills**

-   Experience with Kubernetes and Docker
-   Experience operating in regulated environments such as PCI and SOX
-   Technical certifications or other demonstrations of passion in technology (e.g., AWS Associate, open source projects, or equivalent)

**Responsibilities**

-   Develop internal tools to supplement or enhance capabilities of our core observability products
-   Develop methods to collect telemetry from PlayStation devices and back-end services
-   Build, deploy and operate a combination of open source, custom written, and vendor provided software to support the PlayStation Network platform infrastructure
-   Keep abreast of new observability features, advisories, alerts, trends, and practices
-   Collaborate with PlayStation engineering teams to develop mature observability capabilities
-   Participate in an on-call rotation to ensure 24/7/365 availability of the tools and services delivered by the team

**Desired Sr Site Reliability Engineer (SRE) experience:**

-   AWS services, including EC2, Transit Gateways, NAT Gateways, Elastic Load Balancers, Security Groups, Lambdas, and S3
-   Linux administration and management, particularly in Ubuntu and in RedHat-compatible systems such as CentOS
-   Infrastructure as code (IaC) tools including the Hashicorp ecosystem (Consul, Nomad, Packer, Terraform, and Vault)
-   Configuration management with Saltstack or other tools such as Ansible, Chef, or Puppet
-   Containerization, particularly with Docker, and orchestration and management of containers using Nomad or other tools such as Kubernetes, OpenShift, or Rancher
-   Observability and metrics platforms such as Humio, Prometheus, Telegraf, Vector, Beats, Logstash, Elasticsearch, Grafana, and InfluxDB
-   Confluent Kafka and Confluent Kafka Connect deployment and management
-   One or more high-level languages, such as Python or Ruby
-   General networking; the OSI model, TCP/IP, UDP, routing, NAT, and load balancing
-   OpenVPN, IPSec, and vendor VPN technologies such as Tailscale, Pritunl, or Aviatrix
-   Automation and Continuous Integration (CI) tools such as GitHub Actions or Jenkins
-   Git and version control workflows, particularly on GitHub

**Hard Requirements for the Sr SRE:**

-   Strong communication and collaboration ability
-   Strong technical and analytical skills
-   The ability to effectively work with minimal direction - individually, within a team, and with other groups
-   Prior experience in system or network administration, SRE/devops, or software development

Must-Have Qualifications:

-   Deep understanding and experience with AWS. GCP or Azure experience a bonus.
-   Familiar with common design patterns in infrastructure - networks, systems, containerization.
-   Understanding of configuration management and orchestration and how to apply in a Kubernetes native world.
-   Passion for identifying and reducing toil through simplification and automation.
-   Desire to improve collaboration and be able to communicate asynchronously.
-   Willingness to create and update documentation to facilitate learning for yourself and the team, with comfort speaking to groups and presenting information.
-   Fluency and comfort in a programming or scripting language and the ability to translate to new languages and tools
-   Familiarity with security practices, methods to secure and increase auditability for systems, applications, and administrative functions
-   Familiarity or some experience with compliance requirements - SOC2, PCI, HIPAA, etc.
-   Experience with and familiarity with common developer workflows and CI a plus
-   Experience with all many different technology stacks - anything in () are examples relevant to our use:
-   Kubernetes (DIY, Managed)
-   Datastores (ElasticSearch, Redis, MongoDB)
-   Coding (JavaScript, Python, Rust, Go)
-   Cloud (AWS, GCP, IBMCloud)
-   Linux (CoreOS/Flatcar, Alpine, Ubuntu, RHEL)
-   CI/CD Tooling (Jenkins, CircleCI, GitHub Actions)
-   Orchestration/Configuration management tools (Razee, Terraform, Ansible, Puppet, Chef)

Required Experience/Skills:

-   University or college education in science, technology, engineering, or equivalent industry experience
-   Strong sense of ownership and dedication to results
-   Willingness to do entry level work, if it's necessary for success
-   Approaches challenges as opportunities and sees every day as an opportunity to become a little bit better
-   Team player with high levels of emotional intelligence, that can work with and influence others without direct authority
-   A proactive approach to spotting problems, areas of improvement, and bottlenecks
-   Ability to adapt to working with a wide array of technologies and languages
-   Excellent verbal and written communication skills and ability to communicate technical subjects to a broad range of stakeholders
-   Knowledge of systems design, performance tuning, DevOps, and site-reliability engineering
-   Ability to program with one or more high level languages, such as Python, Go, Java, C/C++
-   Knowledge of VMware Enterprise, Windows Server, Linux
-   Knowledge of Databases
-   Knowledge of Automation and Monitoring technologies and principles
-   Experience with networking, firewall configuration, and troubleshooting
-   3-5+ years of Linux-based system administration, any cloud computing platform (AWS, Azure, GCP, OpenStack, etc ) OR with demonstrated knowledge of Linux and cloud computing technologies
-   Ability to install, configure, and manage both physical and virtual storage implementations (ZFS, NFS, S3, GCP, EBS)
-   Experience with Systems Lifecycle Management Products (Foreman, Katello, RedHat Satellite)
-   Demonstrated knowledge of configuration management tools like Puppet, Chef and Ansible
-   Experience with DevOps technologies such as Jenkins, Maven, GitHub
-   Conceptual knowledge of containerization services (Docker, Kubernetes)

Desired Experience/Skills:

-   3+ years working with Enterprise Imaging Systems
-   Experience in a Leadership role without direct authority
-   Experience working in an SRE environment
-   Experience setting up and managing processes such as monitoring (Nagios/Check_MK), backup, patching etc.
-   Experience with any Microsoft Windows OS and development tools such as Visual Studio
-   Knowledge of Infrastructure as Code (IaC) tools such as Terraform
-   Experience with security products (Crowdstrike, Nessus, Trend Micro Deep Security)
-   Experience supporting 24/7/365 environments
-   Strong software and cloud computing security skills
-   Experience with sharding and data scalability for Postgres DB
-   Strong understanding of medical imaging, radiology workflow, and integration using industry concepts:
-   PACS
-   RIS
-   DICOM
-   HL7 and interface engines
-   HIPAA/HITECH
-   IHE profiles
-   EMR/EHR
-   3rd party vendor integrations

**Responsibilities**

-   You will create monitoring, alerting and dashboarding solutions that improve visibility into EA's application performance and business metrics.
-   You will help design and develop robust, supportable tools to automate the deployment and management of distributed, large-scale production systems on cloud services.
-   You will perform root cause analysis and post-mortems with an eye towards future prevention.
-   You will use automation technologies to ensure repeatability, eliminate toil, reduce mean time to detection and resolution (MTTD & MTTR) and repair services.
-   You will produce documentation and support tooling for online support teams.

**Qualifications**

-   5+ years of experience monitoring infrastructure and application availability to ensure SLI and SLO.
-   3+ years of experience with managing cloud-based service infrastructure and software using Kubernetes and Docker.
-   Strong understanding of *nix operating systems.
-   Network experience, including an understanding of standard protocols/components.
-   Familiarity with common infrastructure and software deployment automation tools such as Terraform, Helm and ArgoCD.
-   Experience writing code in Golang, Python, or Java and scripting with Bash.
-   Experience working with distributed systems.

```

-   2+ years of experience with networking, server infrastructure, or database operations and troubleshooting
-   Experience with configuring and integrating Microsoft Active Directory, DNS, SQL, or enterprise network services
-   Experience with AWS, AWS Tools for Windows PowerShell or Azure
-   Experience with Agile and DevOps development methodologies
-   Experience with build, deployment and release automation, and orchestration, including scripted server builds
-   Experience with automation tools, including Selenium, Jenkins, Puppet, Chef, and Ansible
-   Experience with supporting DoD programs and systems with STIG implementation and analyzing daily processes, including testing, backup, and deployment
-   Experience with Microsoft Windows Server or Linux
-   Knowledge of automation and process improvement through programming holistic solutions, including identifying and implementing automation that delivers value
-   VMware or Microsoft Windows Server 2008 or newer MCSA Certification
```


```

• You will have hands-on experience taking requirements and designing, architecting and implementing reusable and robust solutions.
• 5+ years of experience with AWS. Bonus points for experience with lambdas, API gateway, and other serverless technologies.
• Hands- on experience building infrastructure with IAC tooling.
• Strong experience with Typescript. Java and Spring Boot as well will be a distinct advantage.
• 5+ years of experience in building software products
• 3+ years of experience of working in an SRE capacity within AWS preferably a distinct advantage.
• 3+ years of experience with agile systems development methodologies.
• Experience using and building CI/CD pipelines
• Experience with monitoring tools and solutions. Experience building new monitoring pipelines and tooling a distinct advantage
• Experience with DevOps capabilities
• Strong communication and presentation skills
```


```

Design, implement, and maintain highly available and scalable systems on AWS, ensuring optimal performance, reliability, and security.
Collaborate with development, operations, and security teams to drive DevOps practices and implement CI/CD pipelines, automation, and infrastructure as code (IaC) solutions.
Develop and maintain monitoring, logging, and alerting systems to proactively detect and resolve incidents, minimize downtime, and optimize system performance.
Lead incident response efforts, perform root cause analysis, and implement preventive measures to mitigate risks and improve system stability.
Implement and maintain effective security controls, including access management, authentication, authorization, encryption, and vulnerability management, to protect our systems and data.
Participate in capacity planning, performance tuning, and optimization efforts to ensure efficient resource utilization and cost effectiveness of our AWS infrastructure.
Provide technical expertise and guidance to junior team members, conduct code reviews, and promote best practices for software development, infrastructure management, and security.
Stay up-to-date with industry trends, emerging technologies, and best practices related to AWS, DevOps, security, and access management, and share knowledge with the team.


Bachelor's or Master's degree in Computer Science, Information Technology, or related field.
Minimum of 7 years of professional experience in Site Reliability Engineering or related roles,with a strong focus on AWS, DevOps, security, and access management.
Strong hands-on experience with AWS services, such as EC2, S3, RDS, CloudFormation,CloudWatch, IAM, and VPC, and expertise in designing, deploying, and managing cloud-based
infrastructure.
Proven experience with DevOps practices, including continuous integration, continuous delivery, infrastructure as code (IaC), and automation tools, such as Jenkins, Git, Terraform, and Ansible.
Solid understanding of security best practices and experience in implementing security controls on AWS, such as authentication, authorization, encryption, and vulnerability management.

Strong scripting and programming skills in one or more languages, such as Python, Bash, or PowerShell, for automating tasks and developing infrastructure solutions.
Excellent troubleshooting, debugging, and problem-solving skills, with a keen attention to detail and ability to analyze complex systems and identify performance bottlenecks and security vulnerabilities.
Strong communication and collaboration skills, with the ability to work effectively in a cross-functional, agile team environment.
AWS certifications, such as AWS Certified DevOps Engineer, AWS Certified Security - Specialty, or AWS Certified Solutions Architect, are highly desirable.
If you are a highly motivated and experienced Site Reliability Engineer who is passionate about AWS, DevOps, security, and access management, and you thrive in a fast-paced, collaborative
environment, we would love to hear from you. Apply now to join our team of skilled professionals and help us ensure the reliability and security of our cloud-based systems.
```


```
**Skills And Qualifications  
**

-   Excellent communication skills and a sense of ownership
-   4+ years of relevant professional experience. You have a software engineering background and/or an operations background and have worked as an SRE or related role before
-   Experience architecting, developing, and troubleshooting distributed systems
-   Fluency on design patterns to build performant, resilient and highly available systems
-   Proficient software developer, you not only have the ability to read and write code, but also identify opportunities and implement sound solutions to automate routine tasks and eliminate toil
-   Experience with system architecture. You can create a design document for a performant and highly available application, involving multiple types of storage, cross-region load-balancing, caching layers and messaging infrastructure
-   Excitement for blockchain and Web 3.0
-   Be willing to go on-call. Reliability is our most important feature, because on-call is an essential component of a reliable system we take it very seriously  
      
    

**Preferred Qualifications  
**

-   Professional experience with Golang, TypeScript, or both
-   Experience running blockchain full node operator is a big plus
-   Experience with Chainlink as a developer or a node operator is a big plus
-   Comfort working with network protocols, proxies, and load balancers
-   Experience with CI/CD pipelines. You've worked on both software delivery and cloud-based services deployment
-   Experience with information security and DevSecOps
-   Experience working remotely in a distributed team
-   Experience with container orchestration

-   AWS; Terraform/Terragrunt; Kubernetes, Calico and ArgoCD; Prometheus and Grafana; GitHub Actions; Packer
```


```
-   Service-Level Objectives (SLI, SLO, SLA, Error Budget, Burn Rate)
-   Distributed Systems (architectures, hybrid environments, high-availability)
-   Configuration Management (Puppet, Hiera, Terraform, Ansible)
-   Container Computing (Docker, Kubernetes)
-   Cloud Services and Architecture (AWS, GCP, OpenStack)
-   Distributed Message Bus (RabbitMQ, Kafka)
-   Proxies and Load Balancing (Nginx, HAProxy, ELB, ALB)
-   Monitoring (Prometheus, Kibana, Grafana, Elasticsearch)
-   Logging (Splunk, SysLog, ELK Stack, Linux Journal)
-   Source Control (GitHub Enterprise, Perforce)
-   CI/CD (Jenkins, Argo)
-   Linux (bash, debugging, performance tuning)
-   Networking (triaging, packet loss, routing)
-   Programming (Python, Go, C++, Shell)

```



```
The successful candidate will need:  
  

-   Prior full-time, hands-on experience managing a Kubernetes cluster in a production environment.
-   Deep working knowledge of Kubernetes administration concepts and services like CoreDNS.
-   Proficiency with tools related to Kubernetes like kubectl, k9s, Helm, and CFSSL.
-   Proficiency with Infrastructure-as-Code tools like Terraform or CloudFormation.
-   Proficiency with Git and CI/CD tools like GitLab or Bitbucket.
-   The ability to quickly track down issues with automated deployments and distributed systems.
-   The ability to understand and explain complex AWS architectures.
-   The ability to work independently and balance multiple priorities.
-   A desire to collaborate across continents, share what’s learned, and demonstrate accomplishments.
-   Excellent written and verbal communication skills.  
      
    

Highly-qualified candidates will have:  
  

-   Experience with monitoring and observability tools like Prometheus, Grafana, and Datadog.
-   Experience with logging and analysis tools ElasticSearch / OpenSearch.
-   Proficiency using a variety of AWS services.
-   Proficiency coding in a language like Python or Node.js.
-   Familiarity with REST API concepts and terminology.
```


```
-   Experience with Kubernetes (Kustomize, Helm) in production
-   Experience with observability platforms (Prometheus, Grafana, ELK, Datadog, etc.)
-   Experience writing code in Shell, Go, Python or a similar language
-   Experience with distributed storage technologies like NFS, S3
-   Experience with VMWare and AWS, GCP (or other public cloud platform)
-   A proactive approach to spotting problems, areas for improvement, and performance bottlenecks
-   Excellent debugging and troubleshooting skills
-   At least 5 years of experience in production environments
```
```
-   3-5 years experience with AWS and Linux Systems Administration.
-   In-Depth knowledge on AWS services including VPC, IAM, EC2, EKS, S3, and others.
-   A background building distributed, server-based infrastructure supporting a high volume of transactions in a critical environment.
-   Experience scripting and automating using Python.
-   Experience with Terraform, CloudFormation, Ansible.
-   Excellent understanding of microservices architecture.
-   Excellent interpersonal and communications skills.
-   OpenVPN, LDAP experience a plus.
```



• Participate in an on-call rotation to ensure 24/7/365 availability of SHEIN's production system • Supervise capacity & utilization and work closely with cross-functional teams to orchestrate scale-up/down of the services • Own & operate critical open-source services like Elasticsearch, Kafka, RabbitMQ, Redis • Build tools and design processes that help improve observability and system resiliency of the platform • Triage Site Availability Incidents and proactively work towards reducing MTTR for customer impacting incidents • Partner with Service owners to implement Service Level Metrics & Service Level Objectives that act as service level health indicators • Establish design patterns for monitoring, benchmarking and deploying new features for the backend services • Develop and maintain technical documentation, network diagrams, runbooks, and procedures • Driving initiatives to evolve our current platform to increase efficiency and keep it in line with current standards and best practices • Responding to production incidents and using your experience in software development, systems engineering, and networking to proactively prevent repeatable issues • Provide relief and sustainable resolution to issues within our infrastructure • Drive initiatives with partner teams to improve the reliability and performance of the infrastructure through improved system design • Join a culture of intolerance to manual activity which results in a highly automated environment delivering scalable solutions • Drive efficiencies through software improvement and root cause analysis resulting in service delivery, maturity, and scalability